{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Python 資料科學學習手冊\n",
    "\n",
    "> Python 機器學習模組\n",
    "\n",
    "[數聚點](https://www.datainpoint.com) | 郭耀仁 <yaojenkuo@datainpoint.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 關於 Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 Scikit-Learn\n",
    "\n",
    "> Scikit-learn 是 Python 機器學習的第三方模組，透過它可以進行監督式以及非監督式學習，提供了模型訓練、資料預處理、模型選擇以及模型評估等功能。\n",
    "\n",
    "來源：<https://scikit-learn.org>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 根據說明文件的範例載入\n",
    "\n",
    "多數時候我們使用 Scikit-Learn 中的特定類別或函數，因此以 `from sklearn import FUNCTION/CLASS` 載入特定類別或函數，而非 `import sklearn`\n",
    "\n",
    "來源：<https://scikit-learn.org/stable/getting_started.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 為什麼選擇 Scikit-Learn\n",
    "\n",
    "- 簡潔、一致且設計良善的應用程式介面設計，只要理解基礎用法和語法，就能延伸切換到其他的演算法或模型。\n",
    "- 文件撰寫完整而豐富。\n",
    "- 維護良善。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-Learn 應用程式介面設計原則\n",
    "\n",
    "1. 一致性。\n",
    "2. 可檢查性。\n",
    "3. 不擴增新類別。\n",
    "4. 可組合性。\n",
    "5. 合理預設參數。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 什麼是機器學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 機器學習的三個要素、一個但書\n",
    "\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "來源：[Machine Learning, Tom Mitchell, McGraw Hill, 1997](http://www.cs.cmu.edu/~tom/mlbook.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 傳統透過電腦程式解決問題的方式示意圖\n",
    "\n",
    "![Imgur](https://i.imgur.com/3pojPXW.png?1)\n",
    "\n",
    "來源：<https://www.coursera.org/learn/introduction-tensorflow>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 給定規則 $w$ 以及資料 $X$，我們就可以定義出函數 $f$ 生成答案 $y$\n",
    "\n",
    "\\begin{equation}\n",
    "y = f(X;w) = Xw\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 以機器學習的電腦程式解決問題的方式示意圖\n",
    "\n",
    "![Imgur](https://i.imgur.com/YunyLd7.png)\n",
    "\n",
    "來源：<https://www.coursera.org/learn/introduction-tensorflow>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 給定答案 $y$ 以及資料 $X$，機器學習的電腦程式在最小化損失函數 $J$ 的前提下生成規則 $w$，進而獲得預測 $\\hat{y}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{choose} \\; w \\in \\{w^1, w^2, ..., w^n\\} \\\\\n",
    "\\text{where} \\; w \\; \\text{minimizes} \\; J(w) \\\\\n",
    "\\text{subject to} \\; \\hat{y} = h(X; w) = Xw \\\\\n",
    "\\text{where} \\; J(w) \\; \\text{measures the loss between} \\; y \\; \\text{and} \\; \\hat{y} \\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測數值時最常見的損失函數 $J$\n",
    "\n",
    "最小化均方誤差（Mean squared error）。\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname*{arg\\,min}_w \\;  J(w) =  \\frac{1}{m} \\sum_i^m (y_i - \\hat{y_i})^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測類別時最常見的損失函數 $J$\n",
    "\n",
    "最小化預測錯誤個數。\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname*{arg\\,min}_w \\; J(w) = \\sum_j n(E_j) \\text{ where } E_j \\; \\text{represents the occurrence of } y_j \\neq \\hat{y_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 機器學習的資料表達"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 特徵矩陣與目標陣列\n",
    "\n",
    "- 外型 `(m, n)` 的特徵矩陣 $X$\n",
    "- 外型 `(m,)` 的目標陣列 $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_X_y():\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "    ax.axis('off')\n",
    "    ax.axis('equal')\n",
    "    # Draw features matrix\n",
    "    ax.vlines(range(6), ymin=0, ymax=9, lw=1)\n",
    "    ax.hlines(range(10), xmin=0, xmax=5, lw=1)\n",
    "    font_prop = dict(size=12, family='monospace')\n",
    "    ax.text(-1, -1, \"Feature Matrix ($X$)\", size=14)\n",
    "    ax.text(0.1, -0.3, r'n_features $\\longrightarrow$', **font_prop)\n",
    "    ax.text(-0.1, 0.1, r'$\\longleftarrow$ m_samples', rotation=90,\n",
    "            va='top', ha='right', **font_prop)\n",
    "    # Draw labels vector\n",
    "    ax.vlines(range(8, 10), ymin=0, ymax=9, lw=1)\n",
    "    ax.hlines(range(10), xmin=8, xmax=9, lw=1)\n",
    "    ax.text(7, -1, \"Target Array ($y$)\", size=14)\n",
    "    ax.text(7.9, 0.1, r'$\\longleftarrow$ m_samples', rotation=90,\n",
    "            va='top', ha='right', **font_prop)\n",
    "    ax.set_ylim(10, -2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 來源：<https://jakevdp.github.io/PythonDataScienceHandbook>\n",
    "plot_X_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 如何從 `DataFrame` 中擷取特徵矩陣與目標陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_url = \"https://raw.githubusercontent.com/datainpoint\\\n",
    "/classroom-hahow-pythonfiftyplus/main/data/nba/player_stats.csv\"\n",
    "player_stats = pd.read_csv(csv_url) # import data\n",
    "print(type(player_stats))\n",
    "print(player_stats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `player_stats` NBA 球員的基本資訊與生涯攻守數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "player_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = player_stats[[\"apg\", \"rpg\"]].values # select 2 columns\n",
    "y = player_stats[\"pos\"].values          # select 1 column\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = player_stats[\"heightMeters\"].values.reshape(-1, 1) # select 1 column\n",
    "y = player_stats[\"weightKilograms\"].values             # select 1 column\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 使用轉換器預處理資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 轉換器與預測器是 Scikit-Learn 所創造最重要的兩種類別\n",
    "\n",
    "1. **轉換器（Transformers）：用來預處理資料**。\n",
    "2. 預測器（Predictors）：用來訓練模型、生成規則 $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 轉換器的標準步驟\n",
    "\n",
    "1. 準備欲轉換的特徵矩陣 $X$ 或目標陣列 $y$\n",
    "2. 建立轉換器類別的物件。\n",
    "3. 將欲轉換的特徵矩陣 $X$ 或目標陣列 $y$ 輸入 `transformer.fit_transform()`\n",
    "4. 檢查轉換結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 轉換器 `PolynomialFeatures`\n",
    "\n",
    "生成一個指定次方數的特徵多項式矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X = player_stats[\"heightMeters\"].values.reshape(-1, 1) # step 1\n",
    "polynomial_features = PolynomialFeatures()             # step 2\n",
    "X_transformed = polynomial_features.fit_transform(X)   # step 3\n",
    "print(X_transformed[:5])                               # step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 轉換器 `StandardScaler`\n",
    "\n",
    "生成一個經過 z-score 標準化的特徵矩陣。\n",
    "\n",
    "\\begin{equation}\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = player_stats[\"heightMeters\"].values.reshape(-1, 1) # step 1\n",
    "standard_scaler = StandardScaler()                     # step 2\n",
    "X_transformed = standard_scaler.fit_transform(X)       # step 3\n",
    "print(X_transformed[:5])                               # step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 使用預測器訓練及預測資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 轉換器與預測器是 Scikit-Learn 所創造最重要的兩種類別\n",
    "\n",
    "1. 轉換器（Transformers）：用來預處理資料。\n",
    "2. **預測器（Predictors）：用來訓練模型、生成規則 $w$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器的標準步驟\n",
    "\n",
    "1. 準備欲訓練預測的特徵矩陣 $X$  與目標陣列 $y$\n",
    "2. 切割訓練與驗證資料。\n",
    "3. 建立預測器類別的物件。\n",
    "4. 將訓練特徵矩陣 $X^{train}$ 與目標陣列 $y^{train}$ 輸入 `predictor.fit()`\n",
    "5. 將驗證特徵矩陣 $X^{valid}$ 輸入 `predictor.predict()` 獲得 $\\hat{y}^{valid}$\n",
    "6. 比對 $\\hat{y}^{valid}$ 與 $y^{valid}$ 之間的差異"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 關於切割訓練與驗證資料\n",
    "\n",
    "- 訓練資料：具有實際值或標籤的已實現歷史資料。\n",
    "- 驗證資料：具有實際值或標籤的已實現歷史資料，但是在使用上偽裝成不具有實際值或標籤的待預測資料。\n",
    "- 使用 `sklearn.model_selection` 的 `train_test_split()` 函數。\n",
    "    - `test_size` 驗證資料比例。\n",
    "    - `random_state` 觀測值洗牌的隨機種子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器 `LinearRegression`\n",
    "\n",
    "- 線性迴歸模型。\n",
    "- 數值預測器：NBA 球員的體重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = player_stats[\"heightMeters\"].values.reshape(-1, 1)                       # step 1\n",
    "y = player_stats[\"weightKilograms\"].values                                   # step 1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42) # step 2\n",
    "linear_regression = LinearRegression()                                       # step 3\n",
    "linear_regression.fit(X_train, y_train)                                      # step 4\n",
    "y_hat = linear_regression.predict(X_valid)                                   # step 5\n",
    "m = y_valid.size                                                             # step 6\n",
    "mean_squared_error = ((y_valid - y_hat)**2).sum()/m                          # step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器 `LogisticRegression`\n",
    "\n",
    "- 羅吉斯迴歸模型。\n",
    "- 類別預測器（分類器）：NBA 球員的鋒衛位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pos_dict = {value: index for index, value in enumerate(player_stats[\"pos\"].unique())}\n",
    "X = player_stats[[\"apg\", \"rpg\"]].values       # step 1\n",
    "y = player_stats[\"pos\"].map(pos_dict).values  # step 1\n",
    "print(player_stats[\"pos\"].unique())\n",
    "print(pos_dict)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42) # step 2\n",
    "logistic_regression = LogisticRegression()                                   # step 3\n",
    "logistic_regression.fit(X_train, y_train)                                    # step 4\n",
    "y_hat = logistic_regression.predict(X_valid)                                 # step 5\n",
    "number_of_misclassification = (y_valid != y_hat).sum()                       # step 6\n",
    "print(number_of_misclassification)                                           # step 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 可檢查性：每個轉換器或預測器都有屬性讓使用者檢視轉換或預測的規則"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(polynomial_features.degree)\n",
    "print(standard_scaler.mean_)\n",
    "print(standard_scaler.scale_)\n",
    "print(linear_regression.intercept_)\n",
    "print(linear_regression.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 關於監督式學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是模型\n",
    "\n",
    "- 模型（Model）是一個類似於「函數」的概念，由參數與運算組成。\n",
    "- 模型的參數以及運算可以透過不同的方式生成，生成方式包含規則敘述與歷史資料訓練。\n",
    "    - 透過規則敘述生成參數以及運算，稱為基於規則的模型（Rule-based model）或稱專家模型。\n",
    "    - 透過歷史資料訓練生成參數以及運算，稱為基於演算法的模型（Algorithm-based model）或稱基於機器學習的模型。\n",
    "- 不同模型除了相互比較，也可以與基準（Baseline）模型比較，常用來作為基準模型的像是基於隨機的黑猩猩模型或稱虛假模型（Dummy model），像是以投擲硬幣、骰子或者射飛鏢來決定模型的輸出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 可以採用哪種模型解決問題\n",
    "\n",
    "- 採用基於規則的模型：\n",
    "    - 問題能用人類語言描述邏輯、撰寫規則。\n",
    "    - 答案不能容忍誤差。\n",
    "- 採用基於機器學習的模型：\n",
    "    - 問題非領域專家不容易描述邏輯、撰寫規則。\n",
    "    - 答案能夠容忍誤差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 可以採用哪種模型解決問題（續）\n",
    "\n",
    "- 採用基於規則的模型：給定整數判斷它是否為奇數、偶數或者質數。\n",
    "- 採用基於機器學習的模型：給定一位 NBA 球員的生涯場均助攻與場均籃板來猜他是中鋒、前鋒、後衛或者能夠打多個位置的搖擺人、中前鋒、雙能衛等鋒衛位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於機器學習的模型可再分為\n",
    "\n",
    "- 監督式學習：訓練資料中具備已實現的數值或標籤。\n",
    "    - 迴歸：數值預測的任務。\n",
    "    - 分類：類別預測的任務。\n",
    "- 非監督式學習：訓練資料中「不」具備已實現的數值或標籤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 數值預測的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 數值預測的任務：迴歸模型\n",
    "\n",
    "- 「數值預測」是「監督式學習」的其中一種應用類型。\n",
    "- 預測的目標向量 $y$ 屬於連續型數值變數。\n",
    "- 更常被稱為「迴歸模型」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測數值時最常見的損失函數 $J$\n",
    "\n",
    "最小化訓練資料的均方誤差（Mean squared error）。\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname*{arg\\,min}_w \\;  J(w) =  \\frac{1}{m} \\sum_i^m (y_i^{(train)} - \\hat{y_i}^{(train)})^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測 NBA 球員的體重\n",
    "\n",
    "- 資料（Experience）：一定數量的球員資料。\n",
    "- 任務（Task）：利用模型預測球員的體重。\n",
    "- 評估（Performance）：模型預測的體重與球員實際體重的誤差大小。\n",
    "- 但書（Condition）：隨著資料觀測值筆數增加，預測誤差應該要減少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "player_stats = pd.read_csv(csv_url)\n",
    "y = player_stats[\"weightKilograms\"].values\n",
    "y.dtype # y is a numeric variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的體重\n",
    "\n",
    "1. 虛假模型。\n",
    "2. 基於規則的專家模型。\n",
    "3. 基於機器學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 虛假模型\n",
    "\n",
    "在 NBA 球員體重全距之間取隨機整數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train, y_valid = train_test_split(y, test_size=0.33, random_state=42)\n",
    "y_max, y_min = y.max(), y.min()\n",
    "y_hat = np.random.randint(low=y_min, high=y_max, size=y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估虛假模型：驗證資料與預測資料的均方誤差\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}_{valid} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(valid)}_i - \\hat{y_i}^{(valid)})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse_dummy = mean_squared_error(y_valid, y_hat)\n",
    "mse_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於規則的專家模型\n",
    "\n",
    "根據 NBA 球員的鋒衛位置取其平均體重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weight_by_pos = player_stats.groupby(\"pos\")[\"weightKilograms\"].mean()\n",
    "mean_weight = player_stats[\"pos\"].map(mean_weight_by_pos).values\n",
    "mean_weight_train, y_hat = train_test_split(mean_weight, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估基於規則的專家模型：驗證資料與預測資料的均方誤差\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}_{valid} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(valid)}_i - \\hat{y_i}^{(valid)})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_expert = mean_squared_error(y_valid, y_hat)\n",
    "mse_expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於機器學習的模型\n",
    "\n",
    "將 `heightMeters` 當作特徵矩陣 $x_i$ 作為體重的預測依據。\n",
    "\n",
    "\\begin{equation}\n",
    "\\operatorname*{arg\\,min}_w \\; \\frac{1}{m}\\sum_{i}^{m}{(y^{(train)}_i - \\hat{y_i}^{(train)})^2} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(train)}_i - x_i^{(train)} w)^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器的標準步驟\n",
    "\n",
    "1. 準備欲訓練預測的特徵矩陣 $X$  與目標陣列 $y$\n",
    "2. 切割訓練與驗證資料。\n",
    "3. 建立預測器類別的物件。\n",
    "4. 將訓練特徵矩陣 $X^{train}$ 與目標陣列 $y^{train}$ 輸入 `predictor.fit()`\n",
    "5. 將驗證特徵矩陣 $X^{valid}$ 輸入 `predictor.predict()` 獲得 $\\hat{y}^{valid}$\n",
    "6. 比對 $\\hat{y}^{valid}$ 與 $y^{valid}$ 之間的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = player_stats[\"heightMeters\"].values.reshape(-1, 1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "y_hat = linear_regression.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估基於機器學習的模型：驗證資料與預測資料的均方誤差\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MSE}_{valid} = \\frac{1}{m}\\sum_{i}^{m}{(y^{(valid)}_i - \\hat{y_i}^{(valid)})^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ml = mean_squared_error(y_valid, y_hat)\n",
    "mse_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的體重：考量哪個模型驗證資料與預測資料的均方誤差最小\n",
    "\n",
    "1. 基於規則的專家模型。\n",
    "2. 基於機器學習的模型。\n",
    "3. 虛假模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse_expert)\n",
    "print(mse_ml)\n",
    "print(mse_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 類別預測的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 類別預測的任務：分類器\n",
    "\n",
    "- 「類別預測」是「監督式學習」的其中一種應用類型。\n",
    "- 預測的目標向量 $y$ 屬於離散型的類別變數。\n",
    "- 更常被稱為「分類器」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測類別時最常見的損失函數 $J$\n",
    "\n",
    "最小化訓練資料的誤分類數。\n",
    "\n",
    "\\begin{align}\n",
    "\\operatorname*{arg\\,min}_w \\; J(w) = \\sum_j n(E^{(train)}_j) \\text{ where } E^{(train)}_j \\; \\text{represents the occurrence of } y^{(train)}_j \\neq \\hat{y^{(train)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 預測 NBA 球員的鋒衛位置\n",
    "\n",
    "- 資料（Experience）：一定數量的球員資料。\n",
    "- 任務（Task）：利用模型預測球員的鋒衛位置。\n",
    "- 評估（Performance）：模型預測的鋒衛位置與球員實際鋒衛位置的誤分類數。\n",
    "- 但書（Condition）：隨著資料觀測值筆數增加，預測誤分類數應該要減少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# players_stats 資料中的 pos\n",
    "player_stats[\"pos\"].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## `player_stats` 資料中的 `pos` 有 7 個不同的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(player_stats[\"pos\"].unique())\n",
    "print(player_stats[\"pos\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 先將多元分類問題簡化為二元分類問題\n",
    "\n",
    "- 鋒衛位置分作後衛（G）與前鋒（F）。\n",
    "- 分別對應整數 1 與整數 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_binary = player_stats[\"pos\"].map(lambda x: 0 if x[0] == \"G\" else 1)\n",
    "y = pos_binary.values\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的鋒衛位置\n",
    "\n",
    "1. 虛假模型。\n",
    "2. 基於規則的專家模型。\n",
    "3. 基於機器學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 虛假模型\n",
    "\n",
    "在 0 與 1 之間取隨機整數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = train_test_split(y, test_size=0.33, random_state=42)\n",
    "y_hat = np.random.randint(0, 2, size=y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估虛假模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_j n(E^{(valid)}_j) \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_dummy = np.sum(y_valid != y_hat)\n",
    "print(errors_dummy)\n",
    "print(y_valid.size)\n",
    "print(errors_dummy / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於規則的專家模型\n",
    "\n",
    "根據 NBA 球員的場均助攻數決定，場均助攻超過平均值則是 0，小於等於平均值則是 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_apg = player_stats[\"apg\"].mean()\n",
    "mean_apg_train_y_hat = player_stats[\"apg\"].map(lambda x: 0 if x > mean_apg else 1).values\n",
    "mean_apg_train, y_hat = train_test_split(mean_apg_train_y_hat, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估專家模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_j n(E^{(valid)}_j) \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_expert = np.sum(y_valid != y_hat)\n",
    "print(errors_expert)\n",
    "print(y_valid.size)\n",
    "print(errors_expert / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於機器學習的模型\n",
    "\n",
    "將 `apg` 與 `rpg` 當作特徵矩陣 $X$ 作為鋒衛位置的預測依據。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 使用 Scikit-Learn 預測器的標準步驟\n",
    "\n",
    "1. 準備欲訓練預測的特徵矩陣 $X$  與目標陣列 $y$\n",
    "2. 切割訓練與驗證資料。\n",
    "3. 建立預測器類別的物件。\n",
    "4. 將訓練特徵矩陣 $X^{train}$ 與目標陣列 $y^{train}$ 輸入 `predictor.fit()`\n",
    "5. 將驗證特徵矩陣 $X^{valid}$ 輸入 `predictor.predict()` 獲得 $\\hat{y}^{valid}$\n",
    "6. 比對 $\\hat{y}^{valid}$ 與 $y^{valid}$ 之間的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = player_stats[[\"apg\", \"rpg\"]].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_hat = logistic_regression.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估基於機器學習的模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_j n(E^{(valid)}_j) \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ml = np.sum(y_valid != y_hat)\n",
    "print(errors_ml)\n",
    "print(y_valid.size)\n",
    "print(errors_ml / y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何預測 NBA 球員的鋒衛位置：考量哪個模型驗證資料與預測資料的誤分類數最少\n",
    "\n",
    "1. 機器學習模型。\n",
    "2. 專家模型。\n",
    "3. 虛假模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_valid.size)\n",
    "print(errors_ml)\n",
    "print(errors_expert)\n",
    "print(errors_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 無法描述規則的任務"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 前面的數值、類別預測任務我們都有建立基於規則的專家模型\n",
    "\n",
    "- 有一些問題無法建立基於規則的專家模型，像是影像分類、語音識別或機器翻譯等，都屬於無法描述規則的任務。\n",
    "- 對人類來說影像分類、語音識別或語言翻譯是很輕易能辦到的，但要寫出其中的規則、邏輯是極其困難的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何處理無法描述規則的任務\n",
    "\n",
    "- 以機器學習領域的一個分支**深度學習**來處理。\n",
    "- 深度學習是一種不需要使用者**直接**決定特徵的最適化方法，而是由深度學習的結構**間接**決定。\n",
    "    - 面對數值或類別的預測任務，若是採用機器學習，係數**直接**由特徵矩陣 $X$ 的欄位個數決定。\n",
    "    - 面對數值或類別的預測任務，若是採用深度學習，係數會改由深度（Depth）、或者稱為層數（Number of layers）決定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是深度學習\n",
    "\n",
    "- 以集合概念來說明的話，深度學習包含於機器學習之中，是機器學習集合的子集合。\n",
    "- 深度學習使用連續且多層的數值轉換從訓練資料中同時進行特徵工程（Feature engineering）以及係數 $w$ 的最適化。\n",
    "- 簡言之，我們可以將深度學習視為一種不需要使用者直接進行「特徵工程」（Feature engineering）的最適化方法，使用者透過定義層數來間接決定特徵工程的規模，當深度學習的層數愈多、單位愈多，意味著特徵工程的規模愈大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 現代的基礎深度學習模型\n",
    "\n",
    "- 基礎深度學習模型由充滿單位（又稱神經元，Neuron）的層數堆疊而成，每層的多個單位會因為目的性而有不同的相連狀態。\n",
    "- 把結構中某一層的所有單位都與前一層以及後一層的所有單位相連，稱為完全連接層（Fully-connected layers）或密集層（Dense layers）。\n",
    "- 深度學習模型具備了層數的結構，模型 $h$ 也成為了有鏈結的關係、係數 $W$ 也成為矩陣外型，而非前述的向量外型。\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} &= h(X; W) \\\\\n",
    "&= h^{(n)}(X;w^{(n)}...(h^{(2)}(X; w^{(2)};(h^{(1)}(X; w^{(1)})))))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 現代的基礎深度學習模型（續）\n",
    "\n",
    "- 其中 $h^{(1)}$ 稱為「輸入層」（Input layer），$ h^{(n)}$ 稱為「輸出層」（Output layer），介於這兩層之間的 $h^{(i)}$ 則稱為「隱藏層」（Hidden layer）。\n",
    "- 深度學習模型與傳統機器學習模型最大的差別，在於是否有隱藏層的存在，意即一個最基本、最淺的深度學習模型至少具有三層。\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{y} &= h(X; W) \\\\\n",
    "&= h^{(3)}(X; w^{(3)}(h^{(2)}(X; w^{(2)}(h^{(1)}(X; w^{(1)})))))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 尋找係數的演算方法\n",
    "\n",
    "- 在機器學習中廣泛使用的演算方法稱為「梯度遞減」（Gradient descent）。\n",
    "- 基本概念是先隨機初始化一組係數向量，在基於降低 $y^{(train)}$ 與 $\\hat{y}^{(train)}$ 之間誤差 $J(w)$ 之目標之下，以迭代方式更新該組係數向量，一直到 $J(w)$ 收斂到局部最小值為止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 機器學習與梯度遞減\n",
    "\n",
    "- 更新係數向量時，並不是盲目亂槍打鳥地試誤（Trial and error）\n",
    "- 根據誤差 $J(w)$ 關於係數向量 $w$ 的偏微分來決定更新的方向性，而更新的幅度大小則由一個大於零、稱為「學習速率」的常數 $\\alpha$ 決定：\n",
    "\n",
    "\\begin{equation}\n",
    "w := w - \\alpha \\frac{\\partial J}{\\partial w}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 深度學習模型與反向傳播\n",
    "\n",
    "- 隱藏層的存在造就了尋找深度學習模型最適的 $W$ 時，跟機器學習的「梯度遞減」有異曲同工的地方。\n",
    "- 同工：\n",
    "    - 起始隨機初始化的 $W$ 所預測目標向量 $\\hat{y}$ 會與實際目標向量 $y$ 相差甚遠，兩者之間的誤差也會很大。\n",
    "- 異曲：\n",
    "    - 透過「反向傳播」（Backpropagation）的演算方法來進行梯度遞減、微調每層的係數。\n",
    "    - 因為深度學習模型中至少有一個「隱藏層」的存在，導致 $\\hat{y}$ 與 $y$ 之間的誤差僅能回饋到前一個隱藏層與輸出層之間的 $W$ 作為更新依據。\n",
    "    - 更前段層數之間 $W$ 的更新依據，則改由後段層數回饋。\n",
    "- 簡言之，我們可以將「反向傳播」類比為專門設計給深度學習模型的梯度遞減演算方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow Keras 與 PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 關於 Tensorflow\n",
    "\n",
    "- TensorFlow 是機器學習與深度學習的後端引擎（Backend engine），由 Google 在 2015 年釋出。\n",
    "- 後端引擎將各種類型的張量運算、成本函數定義、成本函數微分運算、梯度遞減演算法、反向傳播演算法、優化型態的梯度遞減演算法、優化型態的反向傳播演算法等，各種開發者需要客製化自己的深度學習模型所需要的元件定義成為類別或函數。\n",
    "- TensorFlow 相似、齊名的後端引擎有 PyTorch、Theano 與 Microsoft Cognitive Toolkit(CNTK)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 關於 Tensorflow Keras\n",
    "\n",
    "- Keras 是基於機器學習與深度學習的後端引擎所設計之應用程式介面（Application Programming Interface, API），由 François Chollet 在 2015 釋出。\n",
    "- Keras 在最一開始的時候被設計為支援「主流」機器學習與深度學習後端引擎的框架；但目前可以視為 TensorFlow 的應用程式介面。\n",
    "- 所謂的應用程式介面可以理解為後端引擎的包裝函數，讓其所提供的功能更容易被開發者使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 關於 PyTorch\n",
    "\n",
    "- PyTorch 是機器學習與深度學習的後端引擎（Backend engine），由 Meta 在 2016 年釋出。\n",
    "- 將使用難度、客製化彈性定位介於 TensorFlow 1.x 與 Keras 之間的後端引擎。\n",
    "- 強調 Python First、除錯簡易與記憶體管理的優化。\n",
    "    - Python First：需要繼承 PyTorch 定義好的類別，再去客製化自己要的模型，必須有良好的 Python 物件導向觀念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 關於 PyTorch Lightning\n",
    "\n",
    "PyTorch Lightning 是基於 PyTorch 所設計的應用程式介面（Application Programming Interface, API），由 William Falcon 在 2019 釋出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 根據說明文件的範例載入\n",
    "\n",
    "```shell\n",
    "!pip uninstall --yes torch torchaudio torchvision torchtext torchdata\n",
    "!pip install torch torchaudio torchvision torchtext torchdata\n",
    "!pip install pytorch-lightning\n",
    "```\n",
    "\n",
    "來源：<https://keras.io/api>, <https://pytorch.org/docs/2.0/>, <https://lightning.ai/docs/pytorch/stable/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import torch\n",
    "import lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 辨識 Fashion MNIST 圖片的衣服種類\n",
    "\n",
    "- 資料（Experience）：一定數量的衣服圖片。\n",
    "- 任務（Task）：利用模型辨識衣服種類。\n",
    "- 評估（Performance）：模型辨識的衣服種類與實際衣服種類的誤分類數。\n",
    "- 但書（Condition）：隨著資料觀測值筆數增加，預測誤分類數應該要減少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fashion MNIST 圖片資料中的 `label` 有 10 個不同的類別\n",
    "\n",
    "```python\n",
    "fashion_mnist_labels = {\n",
    "    0: \"T-shirt/top\",  # index 0\n",
    "    1: \"Trouser\",      # index 1\n",
    "    2: \"Pullover\",     # index 2 \n",
    "    3: \"Dress\",        # index 3 \n",
    "    4: \"Coat\",         # index 4\n",
    "    5: \"Sandal\",       # index 5\n",
    "    6: \"Shirt\",        # index 6 \n",
    "    7: \"Sneaker\",      # index 7 \n",
    "    8: \"Bag\",          # index 8 \n",
    "    9: \"Ankle boot\"    # index 9\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class ImshowSubplots:\n",
    "    \"\"\"\n",
    "    This class plots 2d-arrays with subplots.\n",
    "    Args:\n",
    "        rows (int): The number of rows of axes.\n",
    "        cols (int): The number of columns of axes.\n",
    "        fig_size (tuple): Figure size.\n",
    "    \"\"\"\n",
    "    def __init__(self, rows, cols, fig_size):\n",
    "        self._rows = rows\n",
    "        self._cols = cols\n",
    "        self._fig_size = fig_size\n",
    "    def im_show(self, X, y, label_dict=None):\n",
    "        \"\"\"\n",
    "        This function plots 2d-arrays with subplots.\n",
    "        Args:\n",
    "            X (ndarray): 2d-arrays.\n",
    "            y (ndarray): Labels for 2d-arrays.\n",
    "            label_dict (dict): Str labels for y if any.\n",
    "        \"\"\"\n",
    "        n_pics = self._rows*self._cols\n",
    "        first_n_pics = X[:n_pics, :, :]\n",
    "        first_n_labels = y[:n_pics]\n",
    "        fig, axes = plt.subplots(self._rows, self._cols, figsize=self._fig_size)\n",
    "        for i in range(n_pics):\n",
    "            row_idx = i % self._rows\n",
    "            col_idx = i // self._rows\n",
    "            axes[row_idx, col_idx].imshow(first_n_pics[i], cmap=\"Greys\")\n",
    "            if label_dict is not None:\n",
    "                axes[row_idx, col_idx].set_title(\"Label: {}\".format(label_dict[first_n_labels[i]]))\n",
    "            else:\n",
    "                axes[row_idx, col_idx].set_title(\"Label: {}\".format(first_n_labels[i]))\n",
    "            axes[row_idx, col_idx].set_xticks([])\n",
    "            axes[row_idx, col_idx].set_yticks([])\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist_labels = {\n",
    "    0: \"T-shirt/top\",  # index 0\n",
    "    1: \"Trouser\",      # index 1\n",
    "    2: \"Pullover\",     # index 2 \n",
    "    3: \"Dress\",        # index 3 \n",
    "    4: \"Coat\",         # index 4\n",
    "    5: \"Sandal\",       # index 5\n",
    "    6: \"Shirt\",        # index 6 \n",
    "    7: \"Sneaker\",      # index 7 \n",
    "    8: \"Bag\",          # index 8 \n",
    "    9: \"Ankle boot\"    # index 9\n",
    "}\n",
    "(x_train, y_train), (x_valid, y_valid) = keras.datasets.fashion_mnist.load_data()\n",
    "iss = ImshowSubplots(3, 5, (8, 6))\n",
    "iss.im_show(x_train, y_train, label_dict=fashion_mnist_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 辨識 Fashion MNIST 圖片的衣服種類\n",
    "\n",
    "1. 虛假模型。\n",
    "2. ~~基於規則的專家模型。~~\n",
    "3. 基於深度學習的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 虛假模型\n",
    "\n",
    "在 0 與 9 之間取隨機整數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.random.randint(0, 10, size=y_valid.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估虛假模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_j n(E^{(valid)}_j) \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_dummy = np.sum(y_valid != y_hat)\n",
    "print(\"Error rate: {:.2f}%\".format((errors_dummy / y_valid.size)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於深度學習的模型：使用 keras 建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_valid = x_valid.astype(\"float32\") / 255\n",
    "x_train = x_train[:, :, :, np.newaxis]\n",
    "x_valid = x_valid[:, :, :, np.newaxis]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=15, validation_split=0.1)\n",
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 評估深度學習的模型：驗證資料與預測資料的誤分類數\n",
    "\n",
    "\\begin{align}\n",
    "\\sum_j n(E^{(valid)}_j) \\text{ where } E^{(valid)}_j \\; \\text{represents the occurrence of } y^{(valid)}_j \\neq \\hat{y^{(valid)}_j}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_valid, y_valid)\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "print(\"Error rate: {:.2f}%\".format((1 - accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 基於深度學習的模型：使用 PyTorch Lightning 建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "import torch\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST as MNIST\n",
    "\n",
    "PATH_DATASETS = os.getcwd()\n",
    "if torch.cuda.is_available():\n",
    "    BATCH_SIZE = 256\n",
    "else:\n",
    "    BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class FashionMNISTModel(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, learning_rate=2e-4):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(channels * width * height, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, self.num_classes),\n",
    "        )\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=BATCH_SIZE)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=BATCH_SIZE)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTModel()\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=5,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 該如何辨識 Fashion MNIST 圖片的衣服種類：考量哪個模型驗證資料與預測資料的誤分類數最少\n",
    "\n",
    "1. 深度學習模型。\n",
    "2. 虛假模型。"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
